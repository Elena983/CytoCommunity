{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a5123e-ce1f-4bd0-8e88-ae046d98e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data, InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678fb9d9-566a-4ac5-a7d9-df210b0ffc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputFolderName = \"/home/melnike/Cyto/Python_unbiased/\" \n",
    "KNN_K = 100 # square root of the average number of cells (12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c4343e0-0cca-4419-b3d5-f9648f4c7e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import image name list.\n",
    "Region_filename = InputFolderName + \"ImageNameList.txt\"\n",
    "region_name_list = pd.read_csv(\n",
    "        Region_filename,\n",
    "        sep=\"\\t\",  # tab-separated\n",
    "        header=None,  # no heading row\n",
    "        names=[\"Image\"],  # set our own names for the columns\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c590429-14a4-443a-9e4b-0d70912384f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 06:19:40\n",
      "Constructing topology structures of KNN graphs...\n",
      "This is image-0\n",
      "This is image-1\n",
      "This is image-2\n",
      "All topology structures have been generated!\n",
      "2024-02-18 06:20:04\n"
     ]
    }
   ],
   "source": [
    "## Below is for generation of topology structures (edges) of cellular spatial graphs.\n",
    "ThisStep_OutputFolderName = \"/home/melnike/Cyto/Python_unbiased/Step1_Output/\"\n",
    "if os.path.exists(ThisStep_OutputFolderName):\n",
    "    shutil.rmtree(ThisStep_OutputFolderName)\n",
    "os.makedirs(ThisStep_OutputFolderName)\n",
    "\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print(\"Constructing topology structures of KNN graphs...\")\n",
    "for graph_index in range(0, len(region_name_list)):\n",
    "\n",
    "    print(f\"This is image-{graph_index}\")\n",
    "    # Import target graph x/y coordinates.\n",
    "    region_name = str(region_name_list.Image[graph_index])\n",
    "    GraphCoord_filename = InputFolderName + region_name + \"_Coordinates.txt\"\n",
    "    x_y_coordinates = np.loadtxt(GraphCoord_filename, dtype='float', delimiter=\"\\t\")\n",
    "\n",
    "    K = KNN_K\n",
    "    KNNgraph_sparse = kneighbors_graph(x_y_coordinates, K, mode='connectivity', include_self=False, n_jobs=-1)  #should NOT include itself as a nearest neighbor. Checked. \"-1\" means using all available cores.\n",
    "    KNNgraph_AdjMat = KNNgraph_sparse.toarray()\n",
    "    # Make the graph to undirected.\n",
    "    KNNgraph_AdjMat_fix = KNNgraph_AdjMat + KNNgraph_AdjMat.T  #2min and cost one hundred memory.\n",
    "    # Extract and write the edge index of the undirected graph.\n",
    "    KNNgraph_EdgeIndex = np.argwhere(KNNgraph_AdjMat_fix > 0)  #1min\n",
    "    filename0 = ThisStep_OutputFolderName + region_name + \"_EdgeIndex.txt\"\n",
    "    np.savetxt(filename0, KNNgraph_EdgeIndex, delimiter='\\t', fmt='%i')  #save as integers. Checked the bidirectional edges.\n",
    "    \n",
    "print(\"All topology structures have been generated!\")\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dcd4305-b53a-4b1f-9f8a-71bd15c8f8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating node attribute matrices of KNN graphs...\n",
      "This is processing of CellTypeLabel\n",
      "This is processing of CellTypeLabel\n",
      "This is processing of CellTypeLabel\n",
      "This is processing of MaxNumNodes\n",
      "All files have been generated!\n",
      "2024-02-18 06:22:15\n"
     ]
    }
   ],
   "source": [
    "## Below is for generation of node attribute matrices of cellular spatial graphs.\n",
    "print(\"Generating node attribute matrices of KNN graphs...\")\n",
    "cell_type_vec = []\n",
    "num_nodes = []\n",
    "for graph_index in range(0, len(region_name_list)):\n",
    "\n",
    "    print(\"This is processing of CellTypeLabel\")\n",
    "    region_name = str(region_name_list.Image[graph_index])\n",
    "    # Import cell type label.\n",
    "    CellType_filename = InputFolderName + region_name + \"_CellTypeLabel.txt\"\n",
    "    cell_type_label = pd.read_csv(\n",
    "        CellType_filename,\n",
    "        sep=\"\\t\",  # tab-separated\n",
    "        header=None,  # no heading row\n",
    "        names=[\"cell_type\"],  # set our own names for the columns\n",
    "    )\n",
    "    cell_type_vec.extend(cell_type_label[\"cell_type\"].values.tolist())\n",
    "    num_nodes.append(len(cell_type_label))\n",
    "\n",
    "cell_type_vec_uniq = list(set(cell_type_vec))  # generate a vector of unique cell types and store it to .txt for final illustration.\n",
    "CellTypeVec_filename = ThisStep_OutputFolderName + \"UniqueCellTypeList.txt\"\n",
    "with open(CellTypeVec_filename, 'w') as fp:\n",
    "    print(\"This is processing of MaxNumNodes\")\n",
    "    for item in cell_type_vec_uniq:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "max_nodes = math.ceil(max(num_nodes))  # generate the max number of cells and store this value to .txt for the next step.\n",
    "MaxNumNodes_filename = ThisStep_OutputFolderName + \"MaxNumNodes.txt\"\n",
    "with open(MaxNumNodes_filename, 'w') as fp1:\n",
    "    fp1.write(\"%i\\n\" % max_nodes)\n",
    "\n",
    "print(\"All files have been generated!\")\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee0c324-cfa4-498a-a724-1f9034ea7d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is image-0\n",
      "This is image-1\n",
      "This is image-2\n",
      "All node attribute matrices have been generated!\n",
      "2024-02-18 06:22:24\n"
     ]
    }
   ],
   "source": [
    "for graph_index in range(0, len(region_name_list)):\n",
    "\n",
    "    print(f\"This is image-{graph_index}\")\n",
    "    region_name = str(region_name_list.Image[graph_index])\n",
    "    # import cell type label.\n",
    "    CellType_filename = InputFolderName + region_name + \"_CellTypeLabel.txt\"\n",
    "    cell_type_label = pd.read_csv(\n",
    "        CellType_filename,\n",
    "        sep=\"\\t\",  # tab-separated\n",
    "        header=None,  # no heading row\n",
    "        names=[\"cell_type\"],  # set our own names for the columns\n",
    "    )\n",
    "\n",
    "    # initialize a zero-valued numpy matrix.\n",
    "    node_attr_matrix = np.zeros((len(cell_type_label), len(cell_type_vec_uniq)))\n",
    "    for cell_ind in range(0, len(cell_type_label)):\n",
    "        # get the index of the current cell.\n",
    "        type_index = cell_type_vec_uniq.index(cell_type_label[\"cell_type\"][cell_ind])\n",
    "        node_attr_matrix[cell_ind, type_index] = 1  # make the one-hot vector for each cell.\n",
    "\n",
    "    filename1 = ThisStep_OutputFolderName + region_name + \"_NodeAttr.txt\"\n",
    "    np.savetxt(filename1, node_attr_matrix, delimiter='\\t', fmt='%i')  #save as integers.\n",
    "\n",
    "print(\"All node attribute matrices have been generated!\")\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "520019b9-c8ce-449e-8641-b2462356fe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start graph data structure transformation...\n",
      "All graphs have been generated!\n",
      "2024-02-18 06:22:28\n"
     ]
    }
   ],
   "source": [
    "## Below is for transforming input graphs into the data structure required by deep geometric learning. \n",
    "print(\"Start graph data structure transformation...\")\n",
    "# Construct ordinary Python list to hold all input graphs.\n",
    "data_list = []\n",
    "for i in range(0, len(region_name_list)):\n",
    "    region_name = region_name_list.Image[i]\n",
    "\n",
    "    # Import network topology.\n",
    "    EdgeIndex_filename = ThisStep_OutputFolderName + str(region_name) + \"_EdgeIndex.txt\"\n",
    "    edge_ndarray = np.loadtxt(EdgeIndex_filename, dtype = 'int64', delimiter = \"\\t\")\n",
    "    edge_index = torch.from_numpy(edge_ndarray)\n",
    "    #print(edge_index.type()) #should be torch.LongTensor due to its dtype=torch.int64\n",
    "\n",
    "    # Import node attribute.\n",
    "    NodeAttr_filename = ThisStep_OutputFolderName + str(region_name) + \"_NodeAttr.txt\"\n",
    "    x_ndarray = np.loadtxt(NodeAttr_filename, dtype='float32', delimiter=\"\\t\")  #should be float32 not float or float64.\n",
    "    x = torch.from_numpy(x_ndarray)\n",
    "    #print(x.type()) #should be torch.FloatTensor not torch.DoubleTensor.\n",
    "    \n",
    "    data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "    data_list.append(data)\n",
    "\n",
    "print(\"All graphs have been generated!\")\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bf213dd-db86-4d06-9d78-9c1e8ae965fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.loader import DenseDataLoader\n",
    "from torch_geometric.nn import DenseGraphConv, dense_mincut_pool\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "import torch_geometric.transforms as T\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33c7ae2c-931b-4f8f-b1d4-a26d9c7527a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Name = 1\n",
    "Num_TCN = 6\n",
    "Num_Run = 20\n",
    "Num_Epoch = 3000\n",
    "Embedding_Dimension = 128\n",
    "Learning_Rate = 0.0001\n",
    "Loss_Cutoff = -0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43a574b5-cfc8-4693-9e0d-02756adcd818",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image_Name = 3\n",
    "Num_TCN = 6\n",
    "Num_Run = 20\n",
    "Num_Epoch = 3000\n",
    "Embedding_Dimension = 128\n",
    "Learning_Rate = 0.0001\n",
    "Loss_Cutoff = -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "166e6fa6-2ad1-46f2-8f0f-b914a616ec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 13:36:21\n"
     ]
    }
   ],
   "source": [
    "Region_filename = InputFolderName + \"ImageNameList.txt\"\n",
    "region_name_list = pd.read_csv(\n",
    "        Region_filename,\n",
    "        sep=\"\\t\",  # tab-separated\n",
    "        header=None,  # no heading row\n",
    "        names=[\"Image\"],  # set our own names for the columns\n",
    "    )\n",
    "\n",
    "LastStep_OutputFolderName = \"./Cyto/Python_unbiased/Step1_Output/\"\n",
    "MaxNumNodes_filename = LastStep_OutputFolderName + \"MaxNumNodes.txt\"\n",
    "max_nodes = np.loadtxt(MaxNumNodes_filename, dtype = 'int64', delimiter = \"\\t\").item()\n",
    "\n",
    "class SpatialOmicsImageDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(SpatialOmicsImageDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['SpatialOmicsImageDataset.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        # Read data_list into huge `Data` list.\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "dataset = SpatialOmicsImageDataset(LastStep_OutputFolderName, transform=T.ToDense(max_nodes))\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels=Embedding_Dimension):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = DenseGraphConv(in_channels, hidden_channels)\n",
    "        num_cluster1 = Num_TCN   #This is a hyperparameter.\n",
    "        self.pool1 = Linear(hidden_channels, num_cluster1)\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "\n",
    "        x = F.relu(self.conv1(x, adj, mask))\n",
    "        s = self.pool1(x)  #Here \"s\" is a non-softmax tensor.\n",
    "        x, adj, mc1, o1 = dense_mincut_pool(x, adj, s, mask)\n",
    "        #Save important clustering results_1.\n",
    "        ClusterAssignTensor_1 = s\n",
    "        ClusterAdjTensor_1 = adj\n",
    "\n",
    "        return F.log_softmax(x, dim=-1), mc1, o1, ClusterAssignTensor_1, ClusterAdjTensor_1\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out, mc_loss, o_loss, _, _ = model(data.x, data.adj, data.mask)\n",
    "        loss = mc_loss + o_loss\n",
    "        loss.backward()\n",
    "        loss_all += loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all\n",
    "\n",
    "# Extract a single graph for TCN learning.\n",
    "ThisStep_OutputFolderName = \"./Step2_Output_\" + str(Image_Name) + \"/\"\n",
    "os.makedirs(ThisStep_OutputFolderName, exist_ok=True)\n",
    "\n",
    "train_index = [region_name_list[\"Image\"].values.tolist().index(Image_Name)]\n",
    "train_dataset = dataset[train_index]\n",
    "train_loader = DenseDataLoader(train_dataset, batch_size=1)\n",
    "all_sample_loader = DenseDataLoader(train_dataset, batch_size=1)\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77b205e5-8d48-4afb-b074-b969e2e0844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-18 13:36:30\n",
      "This is Run01\n",
      "Final train loss is -0.6614\n",
      "This is Run02\n",
      "Final train loss is -0.3562\n",
      "This is Run03\n",
      "Final train loss is 0.0879\n",
      "This is Run03\n",
      "Final train loss is -0.3768\n",
      "This is Run04\n",
      "Final train loss is -0.3649\n",
      "This is Run05\n",
      "Final train loss is -0.2315\n",
      "This is Run06\n",
      "Final train loss is -0.2358\n",
      "This is Run07\n",
      "Final train loss is -0.2252\n",
      "This is Run08\n",
      "Final train loss is -0.6366\n",
      "This is Run09\n",
      "Final train loss is -0.3335\n",
      "This is Run10\n",
      "Final train loss is -0.6497\n",
      "This is Run11\n",
      "Final train loss is -0.2212\n",
      "This is Run12\n",
      "Final train loss is -0.6746\n",
      "This is Run13\n",
      "Final train loss is -0.6618\n",
      "This is Run14\n",
      "Final train loss is -0.2098\n",
      "This is Run15\n",
      "Final train loss is -0.3615\n",
      "This is Run16\n",
      "Final train loss is -0.3579\n",
      "This is Run17\n",
      "Final train loss is -0.6539\n",
      "This is Run18\n",
      "Final train loss is -0.3654\n",
      "This is Run19\n",
      "Final train loss is 0.0879\n",
      "This is Run19\n",
      "Final train loss is 0.0879\n",
      "This is Run19\n",
      "Final train loss is -0.6423\n",
      "This is Run20\n",
      "Final train loss is -0.6328\n",
      "2024-02-18 17:41:36\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "run_number = 1\n",
    "while run_number <= Num_Run:  #Generate multiple independent runs for ensemble.\n",
    "\n",
    "    print(f\"This is Run{run_number:02d}\")\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Net(dataset.num_features, 1).to(device)  #Initializing the model.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=Learning_Rate)\n",
    "    \n",
    "    RunFolderName = ThisStep_OutputFolderName + \"Run\" + str(run_number)\n",
    "    if os.path.exists(RunFolderName):\n",
    "        shutil.rmtree(RunFolderName)\n",
    "    os.makedirs(RunFolderName)  #Creating the Run folder.\n",
    "    \n",
    "    filename_0 = RunFolderName + \"/Epoch_UnsupervisedLoss.csv\"\n",
    "    headers_0 = [\"Epoch\", \"UnsupervisedLoss\"]\n",
    "    with open(filename_0, \"w\", newline='') as f0:\n",
    "        f0_csv = csv.writer(f0)\n",
    "        f0_csv.writerow(headers_0)\n",
    "\n",
    "    previous_loss = float(\"inf\")  #Initialization.\n",
    "    for epoch in range(1, Num_Epoch+1):  #Specify the number of epoch in each independent run.\n",
    "        train_loss = train(epoch)\n",
    "        #print(f\"Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}\")\n",
    "        with open(filename_0, \"a\", newline='') as f0:\n",
    "            f0_csv = csv.writer(f0)\n",
    "            f0_csv.writerow([epoch, train_loss])\n",
    "        \n",
    "        if train_loss == 0 and train_loss == previous_loss:  #If two consecutive losses are both zeros, the learning gets stuck.\n",
    "            break  #stop the training.\n",
    "        else:\n",
    "            previous_loss = train_loss\n",
    "\n",
    "    print(f\"Final train loss is {train_loss:.4f}\")\n",
    "    if train_loss >= Loss_Cutoff:   #This is an empirical cutoff of the final loss to avoid underfitting.\n",
    "        shutil.rmtree(RunFolderName)  #Remove the specific folder and all files inside it for re-creating the Run folder.\n",
    "        continue  #restart this run.\n",
    "\n",
    "    #Extract the soft TCN assignment matrix using the trained model.\n",
    "    for EachData in all_sample_loader:\n",
    "        EachData = EachData.to(device)\n",
    "        TestModelResult = model(EachData.x, EachData.adj, EachData.mask)\n",
    "\n",
    "        ClusterAssignMatrix1 = TestModelResult[3][0, :, :]\n",
    "        ClusterAssignMatrix1 = torch.softmax(ClusterAssignMatrix1, dim=-1)  #Checked, consistent with the built-in function \"dense_mincut_pool\".\n",
    "        ClusterAssignMatrix1 = ClusterAssignMatrix1.detach().numpy()\n",
    "        filename1 = RunFolderName + \"/TCN_AssignMatrix1.csv\"\n",
    "        np.savetxt(filename1, ClusterAssignMatrix1, delimiter=',')\n",
    "\n",
    "        ClusterAdjMatrix1 = TestModelResult[4][0, :, :]\n",
    "        ClusterAdjMatrix1 = ClusterAdjMatrix1.detach().numpy()\n",
    "        filename2 = RunFolderName + \"/TCN_AdjMatrix1.csv\"\n",
    "        np.savetxt(filename2, ClusterAdjMatrix1, delimiter=',')\n",
    "\n",
    "        NodeMask = EachData.mask\n",
    "        NodeMask = np.array(NodeMask)\n",
    "        filename3 = RunFolderName + \"/NodeMask.csv\"\n",
    "        np.savetxt(filename3, NodeMask.T, delimiter=',', fmt='%i')  #save as integers.\n",
    "\n",
    "    run_number = run_number + 1\n",
    "\n",
    "print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f449467-4573-43dd-8797-60d6db5ace12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 is executed in R, return here after\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sci_palettes\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "573b410a-6ae7-4f36-a0c7-8fdb7f9233a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n"
     ]
    }
   ],
   "source": [
    "mpl.rcParams['pdf.fonttype'] = 42     # make text in plot editable in AI.\n",
    "#print(sci_palettes.PALETTES.keys()) # used for checking all color schemes of different journals.\n",
    "print('------')\n",
    "#sci_palettes.PALETTES[\"simpsons_springfield\"]     # see detailed color code\n",
    "sci_palettes.register_cmap(\"simpsons_springfield\")     # register a specific palette for TCN coloring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a656556-1568-40cf-984d-3544e4a6a4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell type is imported\n",
      "Cellular spatial graph is imported\n",
      "Cell type label is imported\n",
      "Final TCN is imported\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameters\n",
    "InputFolderName = \"/home/melnike/Cyto/Python_unbiased/\"\n",
    "Image_Name = '3'\n",
    "\n",
    "\n",
    "## Import the cell type list used for matching color palettes across different cell type plots.\n",
    "unique_cell_type_df = pd.read_csv(\n",
    "        \"./Cyto/Python_unbiased/Step1_Output/UniqueCellTypeList.txt\",\n",
    "        sep=\"\\t\",  # tab-separated\n",
    "        header=None,  # no heading row\n",
    "        names=[\"UniqueCellType\"],  # set our own names for the columns\n",
    "    )\n",
    "UniqueCellType_vec = unique_cell_type_df['UniqueCellType'].values.tolist()\n",
    "print('Cell type is imported')\n",
    "\n",
    "## Import target cellular spatial graph x/y coordinates.\n",
    "GraphCoord_filename = InputFolderName + Image_Name + \"_Coordinates.txt\"\n",
    "x_y_coordinates = pd.read_csv(\n",
    "        GraphCoord_filename,\n",
    "        sep=\"\\t\",  # tab-separated\n",
    "        header=None,  # no heading row\n",
    "        names=[\"x_coordinate\", \"y_coordinate\"],  # set our own names for the columns\n",
    "    )\n",
    "print('Cellular spatial graph is imported')\n",
    "target_graph_map = x_y_coordinates\n",
    "#target_graph_map[\"y_coordinate\"] = 0 - target_graph_map[\"y_coordinate\"]  # for consistent with original paper. Don't do this is also ok.\n",
    "\n",
    "\n",
    "## Import cell type label.\n",
    "CellType_filename = InputFolderName + Image_Name + \"_CellTypeLabel.txt\"\n",
    "cell_type_label = pd.read_csv(\n",
    "        CellType_filename,\n",
    "        sep=\"\\t\",  # tab-separated\n",
    "        header=None,  # no heading row\n",
    "        names=[\"cell_type\"],  # set our own names for the columns\n",
    "    )\n",
    "print('Cell type label is imported')\n",
    "\n",
    "# Add cell type labels to target graph x/y coordinates.\n",
    "target_graph_map[\"Cell_Type\"] = cell_type_label.cell_type\n",
    "# Below is for matching color palettes across different cell type plots.\n",
    "target_graph_map[\"Cell_Type\"] = pd.Categorical(target_graph_map[\"Cell_Type\"], UniqueCellType_vec)\n",
    "\n",
    "\n",
    "## Import the final TCN labels to target graph x/y coordinates.\n",
    "LastStep_OutputFolderName = \"./Cyto/Step3_Output_\" + Image_Name + \"/\"\n",
    "target_graph_map[\"TCN_Label\"] = np.loadtxt(LastStep_OutputFolderName + \"TCNLabel_MajorityVoting.csv\", dtype='int', delimiter=\",\")\n",
    "# Converting integer list to string list for making color scheme discrete.\n",
    "target_graph_map.TCN_Label = target_graph_map.TCN_Label.astype(str)\n",
    "\n",
    "print('Final TCN is imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30a9c343-dd02-4e00-8f21-15c187c51c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot TCN label\n",
      "TCN plots are done\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------Generate plots-------------------------------------------------#\n",
    "ThisStep_OutputFolderName = \"./Step4_Output_\" + Image_Name + \"/\"\n",
    "if os.path.exists(ThisStep_OutputFolderName):\n",
    "    shutil.rmtree(ThisStep_OutputFolderName)\n",
    "os.makedirs(ThisStep_OutputFolderName)\n",
    "\n",
    "print('Plot TCN label')\n",
    "## Plot x/y map with \"TCN_Label\" coloring.\n",
    "TCN_plot = sns.scatterplot(x=\"x_coordinate\", y=\"y_coordinate\", data=target_graph_map, hue=\"TCN_Label\", palette=\"simpsons_springfield\", alpha=1.0, s=20.0, legend=\"full\")   # 20 colors at maximum.\n",
    "# Hide all four spines\n",
    "TCN_plot.spines.right.set_visible(False)\n",
    "TCN_plot.spines.left.set_visible(False)\n",
    "TCN_plot.spines.top.set_visible(False)\n",
    "TCN_plot.spines.bottom.set_visible(False)\n",
    "TCN_plot.set(xticklabels=[])  # remove the tick label.\n",
    "TCN_plot.set(yticklabels=[])\n",
    "TCN_plot.set(xlabel=None)  # remove the axis label.\n",
    "TCN_plot.set(ylabel=None)\n",
    "TCN_plot.tick_params(bottom=False, left=False)  # remove the ticks.\n",
    "# Place legend outside top right corner of the CURRENT plot\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0)\n",
    "# Save the CURRENT figure.\n",
    "TCN_fig_filename1 = ThisStep_OutputFolderName + \"TCN_\" + Image_Name + \".pdf\"\n",
    "plt.savefig(TCN_fig_filename1)\n",
    "TCN_fig_filename2 = ThisStep_OutputFolderName + \"TCN_\" + Image_Name + \".png\"\n",
    "plt.savefig(TCN_fig_filename2)\n",
    "plt.close()\n",
    "print('TCN plots are done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "524de6b7-10b6-474e-be2c-3eb55a97e543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot spatial coordinates\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "print('plot spatial coordinates')\n",
    "## Plot x/y map with \"Cell_Type\" coloring.\n",
    "num_unique_categories = len(target_graph_map[\"Cell_Type\"].unique())\n",
    "palette = sns.color_palette(\"husl\", 8)\n",
    "CellType_plot = sns.scatterplot(x=\"x_coordinate\", y=\"y_coordinate\", data=target_graph_map, hue=\"Cell_Type\", palette=palette, alpha=1.0, s=20.0, legend=\"full\")  # 30 colors at maximum.\n",
    "# Hide all four spines\n",
    "CellType_plot.spines.right.set_visible(False)\n",
    "CellType_plot.spines.left.set_visible(False)\n",
    "CellType_plot.spines.top.set_visible(False)\n",
    "CellType_plot.spines.bottom.set_visible(False)\n",
    "CellType_plot.set(xticklabels=[])  # remove the tick label.\n",
    "CellType_plot.set(yticklabels=[])\n",
    "CellType_plot.set(xlabel=None)  # remove the axis label.\n",
    "CellType_plot.set(ylabel=None)\n",
    "CellType_plot.tick_params(bottom=False, left=False)  # remove the ticks.\n",
    "# Place legend outside top right corner of the CURRENT plot\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', borderaxespad=0)\n",
    "# Save the CURRENT figure.\n",
    "CellType_fig_filename1 = ThisStep_OutputFolderName + \"CellType_\" + Image_Name + \".pdf\"\n",
    "plt.savefig(CellType_fig_filename1)\n",
    "CellType_fig_filename2 = ThisStep_OutputFolderName + \"CellType_\" + Image_Name + \".png\"\n",
    "plt.savefig(CellType_fig_filename2)\n",
    "plt.close()\n",
    "\n",
    "\n",
    "## Export result dataframe: \"target_graph_map\".\n",
    "TargetGraph_dataframe_filename = ThisStep_OutputFolderName + \"ResultTable_\" + Image_Name + \".csv\"\n",
    "target_graph_map.to_csv(TargetGraph_dataframe_filename, na_rep=\"NULL\", index=False) #remove row index.\n",
    "\n",
    "print('All done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyto",
   "language": "python",
   "name": "cyto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
